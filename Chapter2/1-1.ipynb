{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba8058ba",
   "metadata": {},
   "source": [
    "LLMを訓練すための入力テキストを準備\n",
    "=======================\n",
    "テキストをここのワードトークンやサブワードトークンに分割すると、LLM用のベクトル表現にエンコードできる。\n",
    "## トークン化とは？\n",
    "トークン化は、テキストを単語、サブワード、文字などの小さな単位（トークン）に分割するプロセスです。これにより、モデルがテキストを理解し、処理しやすくなります。\n",
    "## トークン化の方法\n",
    "1. **単語トークン化**: テキストをスペースや句読点で区切り、単語ごとに分割します。\n",
    "2. **サブワードトークン化**: 単語をさらに小さな単位に分割します。これにより、未知の単語にも対応しやすくなります。\n",
    "3. **文字トークン化**: テキストを1文字ずつ分割します。これにより、非常に細かいレベルでの解析が可能になります。\n",
    "## トークン化のツール\n",
    "- **NLTK**: Pythonの自然言語処理ライブラリで、トークン化機能を提供しています。\n",
    "- **SpaCy**: 高速で効率的なトークン化をサポートするライブラリです。\n",
    "- **Hugging Face Tokenizers**: 高性能なトークン化ライブラリで、BERTやGPTなどのモデルで使用されます。\n",
    "## トークン化の注意点\n",
    "- トークン化の方法は、使用するモデルやタスクに応じて選択する必要があります。\n",
    "- トークン化の結果は、モデルの性能に大きな影響を与えるため、適切な方法を選ぶことが重要です。\n",
    "## まとめ\n",
    "トークン化は、LLMの訓練において重要なステップです。適切なトークン化方法を選び、テキストを効果的に処理することで、モデルの性能を向上させることができます。\n",
    "\n",
    "バイトペアエンコーディング（BPE）\n",
    "----------------------\n",
    "バイトペアエンコーディング（BPE）は、テキストをトークンに分割するための手法の一つです。BPEは、頻繁に出現する文字のペアを繰り返し結合して、新しいトークンを作成します。これにより、語彙のサイズを制御しつつ、未知の単語にも対応できるようになります。\n",
    "GPT型のLLMで利用されている。\n",
    "\n",
    "LLMをはじめとするディープニューラルネットワークモデルは、Rawなテキストを直接処理できないため、テキストをトークンに分割する必要があります。テキストはカテゴリ刈るデータなので、ニューラルネットワークの実装や訓練に使われる数値計算とは相性が良くない.\n",
    "\n",
    "データをベクトルフォーマットに変換する概念=> 埋め込み（Embedding）\n",
    "特定のニューラルネットワーク層や事前学習済みの別のニューラルネットワークモデルを使って、オーディオ、画像モデルなどの他のデータタイプをベクトルに変換することもできる。\n",
    "埋め込みとは、単語、画像、さらには文章全体といった、離散地のオブジェクトから、連続値のベクトル空間への写像\n",
    "\n",
    "\n",
    "word2vecとは、ニューラルネットワークアーキテクチャを訓練し、目的の単語からその周辺のコンテキストを予測するか、コンテキストの単語群から目的の単語を予測することで、単語の埋め込みを学習する手法です。これにより、単語間の意味的な関係を捉えたベクトル表現が得られます。\n",
    "可視化目的で２次元の単語埋め込みを射影すると、意味的に類似した単語が近くに配置されることがわかります。例えば、「king」と「queen」は「man」と「woman」に対して同じ関係を持つため、これらの単語はベクトル空間でも類似した位置に配置されます。\n",
    "\n",
    "テキストを単語に分割して、単語をトークンに変換し、トークンを埋め込みベクトルに変換する。\n",
    "\n",
    "LLMの訓練のためにトークン化するテキストは、Edith Whartonの小説「The Age of Innocence」の一部です。このテキストは、文学的な内容を含んでおり、LLMが自然言語を理解し生成する能力を向上させるために使用されます。\n",
    "\n",
    "```plaintextThe Age of Innocence by Edith Wharton\n",
    "Copyright 1920 by Edith Wharton\n",
    "Copyright renewed 1948 by Edith Wharton\n",
    "All rights reserved including the right of reproduction in whole or in part in any form.\n",
    "This book is a work of fiction. Names, characters, places and incidents are either the product of the author's imagination or are used fictitiously. Any resemblance to actual persons, living or dead, events, or locales is entirely coincidental.\n",
    "First published in 1920 by D. Appleton and Company, Inc., New York\n",
    "This edition published in 2020 by Public Domain Books\n",
    "www.publicdomainbooks.net\n",
    "```     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "907ca47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "if not os.path.exists(\"the-verdict.txt\"):\n",
    "    url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
    "           \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    "           \"the-verdict.txt\")\n",
    "    file_path = \"the-verdict.txt\"\n",
    "    urllib.request.urlretrieve(url, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b78603e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera. (Though I rather thought it would have been Rome or Florence.)\n",
      "\n",
      "\"The height of his glory\"--that was what the women called it. I can hear Mrs. Gideon Thwing--his last Chicago sitter--deploring his unaccountable abdication. \"Of course it'\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(\"Total number of characters:\", len(raw_text))\n",
    "print(raw_text[:500])  # first 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e3d3040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ' ', 'World!', ' ', 'This', ' ', 'is', ' ', 'a', ' ', 'test-text', ' ', 'with', ' ', 'punctuation.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Hello World! This is a test-text with punctuation.\"\n",
    "result = re.split(r'(\\s)', text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd8da241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello World! This is a test-text with punctuation.']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(r'[,.] | \\s' , text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9fdfa03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello World! This is a test-text with punctuation.']\n"
     ]
    }
   ],
   "source": [
    "result = [item for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "85416b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'World', '!', 'Is', 'this', '--', 'a', 'test?']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello World! Is this-- a test?\"\n",
    "result = re.split(r'([,.:;?_!\"()\\'] |--|\\s)', text)\n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1e23ab",
   "metadata": {},
   "source": [
    "ここまで実装トークン化スキームは、テキストを個々の単語と句読点文字に分割する。この具体例では、サンプルテキストが10個のトークンに分解される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d11d6b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 4286\n",
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\'] |--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(\"Total number of tokens:\", len(preprocessed))\n",
    "print(preprocessed[:30])  # first 20 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c220940",
   "metadata": {},
   "source": [
    "トークンをトークンIDに変換する\n",
    "----------------------\n",
    "Pythonの文字列つから整数表現に変換して、トークンIDを生成する.\n",
    "一意な単語と特殊文字を一意な整数にマッピングする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04ad5ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1258\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "print(\"Vocabulary size:\", vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "529ab717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "('\"Ah', 2)\n",
      "('\"Be', 3)\n",
      "('\"Begin', 4)\n",
      "('\"By', 5)\n",
      "('\"Come', 6)\n",
      "('\"Destroyed', 7)\n",
      "('\"Don\\'t', 8)\n",
      "('\"Gisburns', 9)\n",
      "('\"Grindles.\"', 10)\n",
      "('\"Hang', 11)\n",
      "('\"Has', 12)\n",
      "('\"How', 13)\n",
      "('\"I', 14)\n",
      "('\"I\\'d', 15)\n",
      "('\"If', 16)\n",
      "('\"It', 17)\n",
      "('\"It\\'s', 18)\n",
      "('\"Jack', 19)\n",
      "('\"Money\\'s', 20)\n",
      "('\"Moon-dancers', 21)\n",
      "('\"Mr', 22)\n",
      "('\"Mrs', 23)\n",
      "('\"My', 24)\n",
      "('\"Never', 25)\n",
      "('\"Never,', 26)\n",
      "('\"Of', 27)\n",
      "('\"Oh', 28)\n",
      "('\"Once', 29)\n",
      "('\"Only', 30)\n",
      "('\"Or', 31)\n",
      "('\"That', 32)\n",
      "('\"The', 33)\n",
      "('\"Then', 34)\n",
      "('\"There', 35)\n",
      "('\"This', 36)\n",
      "('\"We', 37)\n",
      "('\"Well', 38)\n",
      "('\"What', 39)\n",
      "('\"When', 40)\n",
      "('\"Why', 41)\n",
      "('\"Yes', 42)\n",
      "('\"You', 43)\n",
      "('\"but', 44)\n",
      "('\"deadening', 45)\n",
      "('\"dragged', 46)\n",
      "('\"effects\"', 47)\n",
      "('\"interesting\"', 48)\n",
      "('\"lift', 49)\n",
      "('\"obituary', 50)\n"
     ]
    }
   ],
   "source": [
    "vocab = {token:integer for integer, token in enumerate(all_words)}\n",
    "for i,item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8b4c93",
   "metadata": {},
   "source": [
    "語彙を使って、新しいテキストをトークンIDに変換すること。\n",
    "LLMの出力を数値からテキストに戻したい場合は、トークンIDを対応するトークンにマッピングする逆の語彙を使う。\n",
    "\n",
    "```plaintext\n",
    "Sample text: \"The Age of Innocence by Edith Wharton\"\n",
    "Tokenized: ['The', 'Age', 'of', 'Innocence', 'by', 'Edith', 'Wharton']\n",
    "Token IDs: [1, 2, 3, 4, 5, 6, 7]\n",
    "``` \n",
    "以下でトークナイザーの実装を行う。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dacca45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c4b95650",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i: s for s, i in vocab.items()}\n",
    "        if \"UNK\" not in self.str_to_int:\n",
    "            unk_id = len(self.str_to_int)\n",
    "            self.str_to_int[\"UNK\"] = unk_id\n",
    "            self.int_to_str[unk_id] = \"UNK\"\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\'] |--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        ids = [self.str_to_int.get(s, self.str_to_int[\"UNK\"]) for s in preprocessed]\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "638f41c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [18, 1103, 699, 614, 853, 65, 1251, 692, 1, 962, 123, 67, 1258, 65, 1258, 188, 589, 879, 675, 674, 67, 107, 1230, 1251, 370, 975, 1258]\n",
      "Decoded: \"It's the last he painted, you know,\" said Mr. UNK, UNK a great picture it is. I wish you could see UNK\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(vocab)  # ←インスタンスは小文字で\n",
    "sample_text = \"\"\"\"It's the last he painted, you know,\" said Mr. Poole, \"and a great picture it is. I wish you could see it.\"\"\"\n",
    "encoded = tokenizer.encode(sample_text)\n",
    "print(\"Encoded:\", encoded)\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(\"Decoded:\", decoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8bfc53",
   "metadata": {},
   "source": [
    "特定のコンテキストに対処するために、特別なトークンを追加する。例えば、訓練データセットには含まれず、従って既存の語彙にも含まれていない新しい未知の単語を表すために、<|unk|>トークンを追加することができる。\n",
    "さらに、<|endoftext|> トークンを追加して、無関係な2つのテキストソースを分離できる。\n",
    "無関係なテキストの間にトークンを追加する。例えば、GPT型のLLMに続く各文書や書籍の前にトークンを挿入するのが一般的。このようにすると、「これらのテキストソースは訓練のために連結されているが、実際は無関係である」ことをLLMが理解しやすくなる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406349fc",
   "metadata": {},
   "source": [
    "複数の独立したテキストソースを扱う時には、それらのテキストの間に<|endoftext|>トークンを挿入する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f9d0b732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1260\n"
     ]
    }
   ],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|unk|>\", \"<|endoftext|>\"])\n",
    "vocab = {token: integer for integer, token in enumerate(all_tokens)}\n",
    "\n",
    "print(len(vocab.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "87a9a449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1255)\n",
      "('your', 1256)\n",
      "('yourself', 1257)\n",
      "('<|unk|>', 1258)\n",
      "('<|endoftext|>', 1259)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "df7b3f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i: s for s, i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\'] |--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int\n",
    "            else \"<|unk|>\" for item in preprocessed\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "87693962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined text: Hello, do you like tea?<|endoftext|>In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \"<|endoftext|>\".join([text1, text2])\n",
    "print(\"Combined text:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "63c990c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1258, 65, 434, 1251, 727, 1258, 1103, 1071, 1098, 825, 1103, 1258]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer2(vocab)\n",
    "print(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7ede8dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|unk|>, do you like <|unk|> the sunlit terraces of the <|unk|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d632c463",
   "metadata": {},
   "source": [
    "BPE(バイトペアエンコーディング)の実装　<-GPT-2, GPT-3で利用されている。\n",
    " tiktokenというライブラリを使う。tiktokenは、Rustのソースコードに基づいてBPEアルゴリズムを非常効率的に実装したもの。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0663053a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /Users/yutokishi/anaconda3/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/yutokishi/anaconda3/lib/python3.10/site-packages (from tiktoken) (2022.7.9)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/yutokishi/anaconda3/lib/python3.10/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yutokishi/anaconda3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yutokishi/anaconda3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yutokishi/anaconda3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yutokishi/anaconda3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6dc46b",
   "metadata": {},
   "source": [
    "tiktokenのBPEトークナイザーをインスタンス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd34ed44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 50256, 818, 262, 4252, 18250, 8812, 2114, 286, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokennizer = tiktoken.get_encoding(\"gpt2\")\n",
    "text = (\n",
    "    \"Hello, do you like tea?<|endoftext|>\"\n",
    "    \"In the sunlit terraces of someunknownPlace.\"\n",
    ")\n",
    "\n",
    "integers = tokennizer.encode(text,allowed_special={\"<|endoftext|>\"})# allowed_special=()で特殊トークンを無効化\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f0af789c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea?<|endoftext|>In the sunlit terraces of someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "strings = tokennizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2272b98",
   "metadata": {},
   "source": [
    "BPEトークナイザは未知の単語がどのようなものであろうと対処できる。\n",
    "BPEベースとなるアルゴリズムは、事前に定義された5位に含ていない単語を、より小さなサブワードトークンに分割することができる。このようにすると、語彙に存在しない単語でも"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "739936ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33901, 86, 343, 86, 220, 959]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokennizer = tiktoken.get_encoding(\"gpt2\")\n",
    "text = (\n",
    "    \"Akwirw ier\"\n",
    ")\n",
    "integers = tokennizer.encode(text)\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3a35dd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akwirw ier\n"
     ]
    }
   ],
   "source": [
    "strings = tokennizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd723cb",
   "metadata": {},
   "source": [
    "BPEは頻出する文字をサブワードにマージし、頻出ささサブワードを単語にマージする。、トークン化できるようになります。例えば、「Akwirw ier」という未知の単語は、「Akw」「ir」「w」「ier」というサブワードに分割され、これらのサブワードは語彙に存在するため、トークン化が可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9633b2c5",
   "metadata": {},
   "source": [
    "スライディングウィンドウアプロ使って、入力変数と目的変数のペアをかか訓練デーかrからタからセットから取り出すををデータローダーを実装する。\n",
    "```python\n",
    "import tiktoken\n",
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "enc_text = tokennizer.encode(raw_text)\n",
    "print(f\"Length of text in characters: {len(raw_text)}\")\n",
    "print(f\"Length of text in tokens: {len(enc_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fed761a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text in characters: 20479\n",
      "Length of text in tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "enc_text = tokennizer.encode(raw_text)\n",
    "print(f\"Length of text in characters: {len(raw_text)}\")\n",
    "print(f\"Length of text in tokens: {len(enc_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0259fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sample = enc_text[50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44da17fe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20b069c4",
   "metadata": {},
   "source": [
    "次単語予測タスクのための入力変数目的変数のペアを作成する最も簡単な方法は、x,yという二つの変数を。。作成することです。\n",
    "xには入力トークンが含まれ、yには(xをシフトさせたもの)次のトークンが含まれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0e2c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e7bb4c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y: [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "context_size =4\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size + 1]\n",
    "print(\"x:\", x)\n",
    "print(\"y:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f5b02942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is [290] the desired output is 4920\n",
      "when input is [290, 4920] the desired output is 2241\n",
      "when input is [290, 4920, 2241] the desired output is 287\n",
      "when input is [290, 4920, 2241, 287] the desired output is 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(f\"when input is {context} the desired output is {desired}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0dda5dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and ->  established\n",
      " and established ->  himself\n",
      " and established himself ->  in\n",
      " and established himself in ->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(tokennizer.decode(context), \"->\", tokennizer.decode([desired]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceac540",
   "metadata": {},
   "source": [
    "トークンを埋め込みに変換する前に必要な残り作業は、効率的なデータローダを実装することだけ。このデータローダは入力変数と目的変数をPyTorchテンソルのペアとして返す。\n",
    "ここで取得したいのは、入力テンソルとターゲットテンソルという2つのテンソルです。\n",
    "入力テンソルには、LLMがみるテキストが含まれており、ターゲットテンソルには、次に来るトークンが含まれています。\n",
    "```python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ae1ee107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self,txt,tokenizer,max_length,stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1:i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11102f85",
   "metadata": {},
   "source": [
    "GPTDatasetV1クラスでは、PytorchのDasetsetクラスを継承し、テキストデータをトークン化して、指定されたコンテキストサイズに基づいて入力とターゲットのペアを生成します。これにより、LLMの訓練に適した形式でデータを提供できます。\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "87e4e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#入力変数と目的変数のペアでバッ生成するデータローダー\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128,shuffle = True, drop_last = True, num_workers = 0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
    "    return dataloader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7f43aeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[   40,   367,  2885,  1464,  1807,  3619,   402,   271, 10899,  2138,\n",
      "           257,  7026, 15632,   438,  2016,   257,   922,  5891,  1576,   438,\n",
      "           568,   340,   373,   645,  1049,  5975,   284,   502,   284,  3285,\n",
      "           326,    11,   287,   262,  6001,   286,   465, 13476,    11,   339,\n",
      "           550,  5710,   465, 12036,    11,  6405,   257,  5527, 27075,    11,\n",
      "           290,  4920,  2241,   287,   257,  4489,    64,   319,   262, 34686,\n",
      "         41976,    13,   357, 10915,   314,  2138,  1807,   340,   561,   423,\n",
      "           587, 10598,   393, 28537,  2014,   198,   198,     1,   464,  6001,\n",
      "           286,   465, 13476,     1,   438,  5562,   373,   644,   262,  1466,\n",
      "          1444,   340,    13,   314,   460,  3285,  9074,    13, 46606,   536,\n",
      "          5469,   438, 14363,   938,  4842,  1650,   353,   438,  2934,   489,\n",
      "          3255,   465, 48422,   540,   450,    67,  3299,    13,   366,  5189,\n",
      "          1781,   340,   338,  1016,   284,  3758,   262,  1988,   286,   616,\n",
      "          4286,   705,  1014,   510,    26,   475,   314,   836,   470,   892,\n",
      "           286,   326,    11,  1770,    13,  8759,  2763,   438,  1169,  2994,\n",
      "           284,   943, 17034,   318,   477,   314,   892,   286,   526,   383,\n",
      "          1573,    11,   319,  9074,    13,   536,  5469,   338, 11914,    11,\n",
      "         33096,   663,  4808,  3808,    62,   355,   996,   484,   547, 12548,\n",
      "           287,   281, 13079,   410, 12523,   286, 22353,    13,   843,   340,\n",
      "           373,   407,   691,   262,  9074,    13,   536, 48819,   508, 25722,\n",
      "           276,    13, 11161,   407,   262, 40123, 18113,   544,  9325,   701,\n",
      "            11,   379,   262,   938,   402,  1617,   261, 12917,   905,    11,\n",
      "          5025,   502,   878,   402,   271, 10899,   338,   366, 31640,    12,\n",
      "            67, 20811,     1,   284,   910,    11,   351, 10953,   287,   607,\n",
      "          2951,    25,   366,  1135,  2236,   407,   804,  2402,   663,   588,\n",
      "           757, 13984,   198,   198,  5779, 28112]]), tensor([[  367,  2885,  1464,  1807,  3619,   402,   271, 10899,  2138,   257,\n",
      "          7026, 15632,   438,  2016,   257,   922,  5891,  1576,   438,   568,\n",
      "           340,   373,   645,  1049,  5975,   284,   502,   284,  3285,   326,\n",
      "            11,   287,   262,  6001,   286,   465, 13476,    11,   339,   550,\n",
      "          5710,   465, 12036,    11,  6405,   257,  5527, 27075,    11,   290,\n",
      "          4920,  2241,   287,   257,  4489,    64,   319,   262, 34686, 41976,\n",
      "            13,   357, 10915,   314,  2138,  1807,   340,   561,   423,   587,\n",
      "         10598,   393, 28537,  2014,   198,   198,     1,   464,  6001,   286,\n",
      "           465, 13476,     1,   438,  5562,   373,   644,   262,  1466,  1444,\n",
      "           340,    13,   314,   460,  3285,  9074,    13, 46606,   536,  5469,\n",
      "           438, 14363,   938,  4842,  1650,   353,   438,  2934,   489,  3255,\n",
      "           465, 48422,   540,   450,    67,  3299,    13,   366,  5189,  1781,\n",
      "           340,   338,  1016,   284,  3758,   262,  1988,   286,   616,  4286,\n",
      "           705,  1014,   510,    26,   475,   314,   836,   470,   892,   286,\n",
      "           326,    11,  1770,    13,  8759,  2763,   438,  1169,  2994,   284,\n",
      "           943, 17034,   318,   477,   314,   892,   286,   526,   383,  1573,\n",
      "            11,   319,  9074,    13,   536,  5469,   338, 11914,    11, 33096,\n",
      "           663,  4808,  3808,    62,   355,   996,   484,   547, 12548,   287,\n",
      "           281, 13079,   410, 12523,   286, 22353,    13,   843,   340,   373,\n",
      "           407,   691,   262,  9074,    13,   536, 48819,   508, 25722,   276,\n",
      "            13, 11161,   407,   262, 40123, 18113,   544,  9325,   701,    11,\n",
      "           379,   262,   938,   402,  1617,   261, 12917,   905,    11,  5025,\n",
      "           502,   878,   402,   271, 10899,   338,   366, 31640,    12,    67,\n",
      "         20811,     1,   284,   910,    11,   351, 10953,   287,   607,  2951,\n",
      "            25,   366,  1135,  2236,   407,   804,  2402,   663,   588,   757,\n",
      "         13984,   198,   198,  5779, 28112, 10197]])]\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text,\n",
    "    batch_size=1,\n",
    "    max_length=256,\n",
    "    stride=1,\n",
    "    shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "17e513d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  367,  2885,  1464,  1807,  3619,   402,   271, 10899,  2138,   257,\n",
      "          7026, 15632,   438,  2016,   257,   922,  5891,  1576,   438,   568,\n",
      "           340,   373,   645,  1049,  5975,   284,   502,   284,  3285,   326,\n",
      "            11,   287,   262,  6001,   286,   465, 13476,    11,   339,   550,\n",
      "          5710,   465, 12036,    11,  6405,   257,  5527, 27075,    11,   290,\n",
      "          4920,  2241,   287,   257,  4489,    64,   319,   262, 34686, 41976,\n",
      "            13,   357, 10915,   314,  2138,  1807,   340,   561,   423,   587,\n",
      "         10598,   393, 28537,  2014,   198,   198,     1,   464,  6001,   286,\n",
      "           465, 13476,     1,   438,  5562,   373,   644,   262,  1466,  1444,\n",
      "           340,    13,   314,   460,  3285,  9074,    13, 46606,   536,  5469,\n",
      "           438, 14363,   938,  4842,  1650,   353,   438,  2934,   489,  3255,\n",
      "           465, 48422,   540,   450,    67,  3299,    13,   366,  5189,  1781,\n",
      "           340,   338,  1016,   284,  3758,   262,  1988,   286,   616,  4286,\n",
      "           705,  1014,   510,    26,   475,   314,   836,   470,   892,   286,\n",
      "           326,    11,  1770,    13,  8759,  2763,   438,  1169,  2994,   284,\n",
      "           943, 17034,   318,   477,   314,   892,   286,   526,   383,  1573,\n",
      "            11,   319,  9074,    13,   536,  5469,   338, 11914,    11, 33096,\n",
      "           663,  4808,  3808,    62,   355,   996,   484,   547, 12548,   287,\n",
      "           281, 13079,   410, 12523,   286, 22353,    13,   843,   340,   373,\n",
      "           407,   691,   262,  9074,    13,   536, 48819,   508, 25722,   276,\n",
      "            13, 11161,   407,   262, 40123, 18113,   544,  9325,   701,    11,\n",
      "           379,   262,   938,   402,  1617,   261, 12917,   905,    11,  5025,\n",
      "           502,   878,   402,   271, 10899,   338,   366, 31640,    12,    67,\n",
      "         20811,     1,   284,   910,    11,   351, 10953,   287,   607,  2951,\n",
      "            25,   366,  1135,  2236,   407,   804,  2402,   663,   588,   757,\n",
      "         13984,   198,   198,  5779, 28112, 10197]]), tensor([[ 2885,  1464,  1807,  3619,   402,   271, 10899,  2138,   257,  7026,\n",
      "         15632,   438,  2016,   257,   922,  5891,  1576,   438,   568,   340,\n",
      "           373,   645,  1049,  5975,   284,   502,   284,  3285,   326,    11,\n",
      "           287,   262,  6001,   286,   465, 13476,    11,   339,   550,  5710,\n",
      "           465, 12036,    11,  6405,   257,  5527, 27075,    11,   290,  4920,\n",
      "          2241,   287,   257,  4489,    64,   319,   262, 34686, 41976,    13,\n",
      "           357, 10915,   314,  2138,  1807,   340,   561,   423,   587, 10598,\n",
      "           393, 28537,  2014,   198,   198,     1,   464,  6001,   286,   465,\n",
      "         13476,     1,   438,  5562,   373,   644,   262,  1466,  1444,   340,\n",
      "            13,   314,   460,  3285,  9074,    13, 46606,   536,  5469,   438,\n",
      "         14363,   938,  4842,  1650,   353,   438,  2934,   489,  3255,   465,\n",
      "         48422,   540,   450,    67,  3299,    13,   366,  5189,  1781,   340,\n",
      "           338,  1016,   284,  3758,   262,  1988,   286,   616,  4286,   705,\n",
      "          1014,   510,    26,   475,   314,   836,   470,   892,   286,   326,\n",
      "            11,  1770,    13,  8759,  2763,   438,  1169,  2994,   284,   943,\n",
      "         17034,   318,   477,   314,   892,   286,   526,   383,  1573,    11,\n",
      "           319,  9074,    13,   536,  5469,   338, 11914,    11, 33096,   663,\n",
      "          4808,  3808,    62,   355,   996,   484,   547, 12548,   287,   281,\n",
      "         13079,   410, 12523,   286, 22353,    13,   843,   340,   373,   407,\n",
      "           691,   262,  9074,    13,   536, 48819,   508, 25722,   276,    13,\n",
      "         11161,   407,   262, 40123, 18113,   544,  9325,   701,    11,   379,\n",
      "           262,   938,   402,  1617,   261, 12917,   905,    11,  5025,   502,\n",
      "           878,   402,   271, 10899,   338,   366, 31640,    12,    67, 20811,\n",
      "             1,   284,   910,    11,   351, 10953,   287,   607,  2951,    25,\n",
      "           366,  1135,  2236,   407,   804,  2402,   663,   588,   757, 13984,\n",
      "           198,   198,  5779, 28112, 10197,   832]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d746d",
   "metadata": {},
   "source": [
    "データセット全ての単語を利用するために、ストライドを４に増やしている。これはバッチ間のオーバーラップを防ぐための措置。オーバーラップが多いと過剰適リスクが高まる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "49dd1f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "Targets: tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text,\n",
    "    batch_size=8,\n",
    "    max_length=4,\n",
    "    stride=4,\n",
    "    shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs,targets = next(data_iter)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Targets:\", targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b54510b",
   "metadata": {},
   "source": [
    "トークン埋め込みを作成する。\n",
    "トークンIDを埋め込みベクトルに変換する。下準備として、埋め込み層の重みをランダム値で初期化する。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "94dc3eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor([2,3,5,1])\n",
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "print(embedding_layer(input_ids))\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "da9b1185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor([3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6e0dd9",
   "metadata": {},
   "source": [
    "単語の位置をエンコードする。\n",
    "トークン埋め込みは、基本的にはLLMの入力に適している。Self-Attentionメカニズムにシーケンス内のトークンの位置や順序という情報が欠けているため、トークンの位置情報を追加する必要がある。トークンIDがシーケンス内のどの位置にあろうと、同じトークンIDを常に同じベクトル表現にマッピングする。\n",
    "相対位置埋め込みと絶対位置埋め込みの2種類がある。絶対位置埋め込み：トークンの位置を固定されたベクトルにマッピングする。例えば、最初のトークンは常に同じベクトル、2番目のトークンは常に別のベクトルにマッピングされる。\n",
    "相対位置埋め込み： トークンの位置を他のトークンとの相対的な位置に基づいてエンコードする。例えば、あるトークンがシーケンス内で3つ目に出現する場合、そのトークンは「3」という位置情報を持つ。トークンの絶絶対位に着目する、ではなく、トークン間の相対的な位置(距離)に着目する。つまり「正確な位置」ではなく、「どれくらい離れているか」という観点からモデルがトークン間の関係を学習する。\n",
    "OpenAIのGPT-2やGPT-3では、絶対位置埋め込みが採用されている。オリジナルのTransformerモデルの位置エンコーディングのように固定値を使うのではなく、訓練プロセスの過程で埋め込みの値を最適化する。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4824701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:  tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "inputs shape:  torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vacab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "#データローダからデータをサンプリングすると、各バッチの各トークンが256次元のベクトルに埋め込まれる。バッチサイズが8、バッチ内の各シーケンスのトークン数が4の場合、結果として8x4x256のテンソルが得られる。\n",
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "     raw_text, batch_size=8, max_length=max_length, stride=max_length,shuffle=False\n",
    " )\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Token IDs: \",inputs)\n",
    "print(\"inputs shape: \" ,inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad91562",
   "metadata": {},
   "source": [
    "トークンIDテンソルは8x4次元であり、データバッチがそれぞれ4つのトークンを持つ8つのテキストサンプルで構成されている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "678b220f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m token_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mtoken_embedding_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(token_embeddings\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/functional.py:2199\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2193\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2194\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2195\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2196\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2197\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2198\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0b66aed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "11 15632\n",
      "Embedding: 6 256\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "max id 15632 >= num_embeddings 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mlong, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs must be torch.long\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative token id found\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m<\u001b[39m num_emb, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax id \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m >= num_embeddings \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_emb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: max id 15632 >= num_embeddings 6"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(inputs.dtype)  # long 以外なら NG\n",
    "print(inputs.min().item(), inputs.max().item())\n",
    "\n",
    "num_emb = token_embedding_layer.num_embeddings\n",
    "emb_dim = token_embedding_layer.embedding_dim\n",
    "print(\"Embedding:\", num_emb, emb_dim)\n",
    "assert inputs.dtype == torch.long, \"inputs must be torch.long\"\n",
    "assert inputs.min().item() >= 0, \"negative token id found\"\n",
    "assert inputs.max().item() < num_emb, f\"max id {inputs.max().item()} >= num_embeddings {num_emb}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "16dfe2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "vocab_size = 50257           # ← 綴り修正\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "537a98d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tokenizer2' object has no attribute 'vocab_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 例: transformers の GPT-2 トークナイザを使っている場合\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# GPT-2 は pad_token が無いので以下のように合わせることが多い\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# tokenizer.pad_token = tokenizer.eos_token\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m  \u001b[38;5;66;03m# 例: 50257（ID範囲は 0..50256）\u001b[39;00m\n\u001b[1;32m      7\u001b[0m token_embedding_layer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mEmbedding(vocab_size, output_dim)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tokenizer2' object has no attribute 'vocab_size'"
     ]
    }
   ],
   "source": [
    "# 例: transformers の GPT-2 トークナイザを使っている場合\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "# GPT-2 は pad_token が無いので以下のように合わせることが多い\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "vocab_size = tokenizer.vocab_size  # 例: 50257（ID範囲は 0..50256）\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9901e568",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3662d982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "bad = (inputs < 0) | (inputs >= token_embedding_layer.num_embeddings)\n",
    "if bad.any():\n",
    "    ids, counts = inputs[bad].unique(return_counts=True)\n",
    "    print(\"Out-of-range ids:\", list(zip(ids.tolist(), counts.tolist())))\n",
    "import torch\n",
    "\n",
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "max_length = 4\n",
    "\n",
    "# ダミー入力（バッチ8、長さ4）: 0..50256 の範囲で作る\n",
    "inputs = torch.randint(0, vocab_size, (8, max_length), dtype=torch.long)\n",
    "\n",
    "emb = torch.nn.Embedding(vocab_size, output_dim)\n",
    "token_embeddings = emb(inputs)\n",
    "print(token_embeddings.shape)  # -> torch.Size([8, 4, 256])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07b2f1d",
   "metadata": {},
   "source": [
    "8x4x256次元のテンソル出力は、各トークンIDが256次元のベクトルとして埋め込まれていたことを示す。\n",
    "GPTモデルが使っている絶対位置埋め込みの場合は、token_embedding_layerと同じ埋め込み次元を持つ別の埋め込み層を作成すれば良い。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3053a2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1f02e1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7631,  0.4319,  0.6108,  ...,  0.3566, -0.7010, -1.9475],\n",
      "         [ 0.6965, -0.1571,  0.0788,  ...,  1.0171,  1.7671, -1.3661],\n",
      "         [-0.5620, -1.9964,  0.0635,  ..., -1.0211,  0.0451, -0.2414],\n",
      "         [ 1.1894, -0.5114,  0.0705,  ...,  2.5368,  0.1625, -3.1906]],\n",
      "\n",
      "        [[ 3.1604,  0.3198,  0.2387,  ..., -0.2770, -0.4700, -2.0030],\n",
      "         [ 2.0893,  0.1209, -0.9477,  ...,  0.3106,  0.1899, -1.4455],\n",
      "         [ 1.0608, -0.8959, -0.2569,  ..., -1.4255, -0.0438,  1.2416],\n",
      "         [ 1.2738, -1.1006,  0.8085,  ...,  1.4476,  2.2197, -2.2340]],\n",
      "\n",
      "        [[ 0.6233,  1.0373,  0.5444,  ...,  1.0107, -0.2704, -0.2196],\n",
      "         [ 2.5480,  1.2801, -1.9756,  ..., -0.8843,  2.3870, -1.8155],\n",
      "         [-0.9067,  0.4186,  0.3427,  ..., -0.3430, -1.5909,  2.0557],\n",
      "         [-0.8647, -2.2094,  0.3977,  ...,  1.7670,  2.1549, -3.0443]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0214, -1.1366, -0.2724,  ...,  1.8278, -0.1046,  0.4288],\n",
      "         [ 0.0891, -0.5787, -1.9916,  ...,  0.3603, -0.4274, -2.5617],\n",
      "         [-1.9423, -0.2294,  0.0825,  ..., -0.6349,  0.2642,  1.7743],\n",
      "         [ 0.6193, -1.2785,  1.1716,  ...,  1.5014,  1.9189, -0.6822]],\n",
      "\n",
      "        [[-0.2411,  1.2358, -0.6216,  ...,  0.9685, -0.4567, -1.3277],\n",
      "         [ 1.4874, -2.7644, -3.6673,  ...,  0.0528,  2.3084, -2.7075],\n",
      "         [-0.4657,  0.6893, -1.5146,  ..., -0.6551, -2.1524,  1.7767],\n",
      "         [-0.1225, -1.2633,  2.4081,  ...,  1.1394,  1.3380, -2.5502]],\n",
      "\n",
      "        [[ 1.1537, -1.5336, -0.5755,  ...,  0.4042,  0.3723, -0.7767],\n",
      "         [ 1.6644, -1.4294, -1.2637,  ...,  0.6091,  1.0743, -1.5666],\n",
      "         [-1.1148, -1.4976,  1.2880,  ...,  0.7250, -1.9924, -0.0746],\n",
      "         [ 1.4705,  1.1503,  0.6472,  ...,  1.7782,  3.2728, -2.7602]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78492145",
   "metadata": {},
   "source": [
    "入力処理パイプラインの一部として、まず入力テキストがここのトぶぶーク分割される。次に、これらのトークンが5位を使ってトークンIDに変換される。　さらに、トークンIDが埋め込みベクトルに変換され、同じサイズの位置埋め込みが加算される。結果として、メイン層の入力として利用できる入力埋め込みが得られる。\n",
    "\n",
    "\n",
    "・LLMはテキストデータを埋め込みと呼ばれる数値ベクトルに変換する必要がある。埋め込みとは(単語や画像のような)離散値のデータを連続値のベクトル空間にマッピングすることで、ニューラルネットワークの演算に適合させる。\n",
    "\n",
    "・Rawテキストがトークンに分割される。トークンは単語の場合と文字の場合がある。次に、トークンがトークンIDと呼ばれる整数表現に変換される。\n",
    "\n",
    "・Pytorchの埋め込み層は、トークンIDに対応するベクトルを取り出すルックアップ演算として機能する。結果として得られる埋め込みベクトルは、トークンの連続値表現を提供する。\n",
    "\n",
    "・トークン埋め込みは、各トークに対して一貫性のあるベクトル表現を提供するが、シーケンス内でのトークンの位置に関する情報を持たない。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b261ee",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
